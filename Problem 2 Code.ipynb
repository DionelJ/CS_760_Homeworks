{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e9faed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3314335192958997, 0.3133925929173471, 0.3551738877867532]\n",
      "a    0.060169\n",
      "b    0.011135\n",
      "c    0.021510\n",
      "d    0.021973\n",
      "e    0.105369\n",
      "f    0.018933\n",
      "g    0.017479\n",
      "h    0.047216\n",
      "i    0.055411\n",
      "j    0.001421\n",
      "k    0.003734\n",
      "l    0.028977\n",
      "m    0.020519\n",
      "n    0.057922\n",
      "o    0.064464\n",
      "p    0.016752\n",
      "q    0.000562\n",
      "r    0.053825\n",
      "s    0.066182\n",
      "t    0.080126\n",
      "u    0.026664\n",
      "v    0.009285\n",
      "w    0.015496\n",
      "x    0.001156\n",
      "y    0.013844\n",
      "z    0.000628\n",
      "     0.179250\n",
      "Name: e, dtype: float64\n",
      "a    0.131766\n",
      "b    0.010867\n",
      "c    0.005486\n",
      "d    0.017226\n",
      "e    0.060205\n",
      "f    0.003879\n",
      "g    0.014012\n",
      "h    0.031762\n",
      "i    0.097033\n",
      "j    0.002341\n",
      "k    0.057409\n",
      "l    0.001433\n",
      "m    0.039799\n",
      "n    0.056711\n",
      "o    0.091163\n",
      "p    0.000874\n",
      "q    0.000105\n",
      "r    0.042804\n",
      "s    0.042175\n",
      "t    0.056990\n",
      "u    0.070617\n",
      "v    0.000245\n",
      "w    0.019742\n",
      "x    0.000035\n",
      "y    0.014151\n",
      "z    0.007722\n",
      "     0.123449\n",
      "Name: j, dtype: float64\n",
      "a    0.104560\n",
      "b    0.008233\n",
      "c    0.037526\n",
      "d    0.039746\n",
      "e    0.113811\n",
      "f    0.008603\n",
      "g    0.007184\n",
      "h    0.004533\n",
      "i    0.049860\n",
      "j    0.006629\n",
      "k    0.000278\n",
      "l    0.052943\n",
      "m    0.025809\n",
      "n    0.054177\n",
      "o    0.072492\n",
      "p    0.024267\n",
      "q    0.007678\n",
      "r    0.059295\n",
      "s    0.065770\n",
      "t    0.035614\n",
      "u    0.033702\n",
      "v    0.005889\n",
      "w    0.000093\n",
      "x    0.002498\n",
      "y    0.007863\n",
      "z    0.002683\n",
      "     0.168265\n",
      "Name: s, dtype: float64\n",
      "e\n",
      "a    164\n",
      "b     32\n",
      "c     53\n",
      "d     57\n",
      "e    311\n",
      "f     55\n",
      "g     51\n",
      "h    140\n",
      "i    140\n",
      "j      3\n",
      "k      6\n",
      "l     85\n",
      "m     64\n",
      "n    139\n",
      "o    182\n",
      "p     53\n",
      "q      3\n",
      "r    141\n",
      "s    186\n",
      "t    225\n",
      "u     65\n",
      "v     31\n",
      "w     47\n",
      "x      4\n",
      "y     38\n",
      "z      2\n",
      "     498\n",
      "dtype: int64\n",
      "-7841.865447060635\n",
      "-8771.433079075032\n",
      "-8467.282044010557\n",
      "      e     j     s\n",
      "e  10.0   0.0   0.0\n",
      "j   0.0  10.0   0.0\n",
      "s   0.0   0.0  10.0\n",
      "      e     j     s\n",
      "e  10.0   0.0   0.0\n",
      "j   0.0  10.0   0.0\n",
      "s   0.0   0.0  10.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from string import ascii_lowercase\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "training_data = [] # each item in data is a list of characters from a document\n",
    "training_labels = [] # each item in labels is the corresponding label 'e', 'j', or 's' of that document\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "alphabet = list(ascii_lowercase) + [' '] #alphabet plus the space\n",
    "\n",
    "# read in text data\n",
    "data_dir = 'languageID'\n",
    "for f in os.listdir(data_dir):\n",
    "    num = int(f[1:-4])\n",
    "    if num <= 9:\n",
    "        #print('train', f)\n",
    "        path = os.path.join(data_dir, f)\n",
    "        chars = []\n",
    "        for c in open(path).read():\n",
    "            if c in alphabet:\n",
    "                chars.append(c)\n",
    "\n",
    "        label = f[0]\n",
    "\n",
    "        training_data.append(chars)\n",
    "        training_labels.append(label)\n",
    "    else:\n",
    "        #print('test', f)\n",
    "        path = os.path.join(data_dir, f)\n",
    "        chars = []\n",
    "        for c in open(path).read():\n",
    "            if c in alphabet:\n",
    "                chars.append(c)\n",
    "\n",
    "        label = f[0]\n",
    "\n",
    "        test_data.append(chars)\n",
    "        test_labels.append(label)\n",
    "\n",
    "classes = sorted(list(set(training_labels)))\n",
    "\n",
    "\n",
    "# get character counts of each document\n",
    "char_counts = []\n",
    "for d in training_data:\n",
    "    counts = {c:d.count(c) for c in alphabet}\n",
    "    char_counts.append(counts)\n",
    "\n",
    "char_counts = pd.DataFrame(char_counts)\n",
    "char_counts['label'] = training_labels\n",
    "\n",
    "# calculate the prior probabilities of each class\n",
    "smoothing_parameter = 0.5\n",
    "sum_counts = char_counts.groupby('label').sum()\n",
    "total_counts = sum_counts.sum(axis=1)\n",
    "prior_probs = (total_counts + smoothing_parameter) / (total_counts.sum() + smoothing_parameter*len(classes))\n",
    "print(list(prior_probs))\n",
    "prior_probs = {}\n",
    "for y in classes:\n",
    "    count_y = training_labels.count(y)\n",
    "    total_count = len(training_labels)\n",
    "    p_y = (count_y + smoothing_parameter) / (total_count + smoothing_parameter * len(classes))\n",
    "    prior_probs[y] = p_y\n",
    "prior_probs = pd.DataFrame.from_dict(prior_probs, orient='index')\n",
    "\n",
    "\n",
    "smoothing_parameter = 0.5\n",
    "sum_counts = char_counts.groupby('label').sum()\n",
    "total_counts = sum_counts.sum(axis=1)\n",
    "class_cond_probs = (sum_counts + smoothing_parameter).divide(\n",
    "    total_counts + smoothing_parameter * len(alphabet), axis='rows')\n",
    "print(class_cond_probs.loc['e'])\n",
    "print(class_cond_probs.loc['j'])\n",
    "print(class_cond_probs.loc['s'])\n",
    "\n",
    "# function to predict the label of a test input x\n",
    "def predict(x):\n",
    "    char_counts_x = {c: x.count(c) for c in alphabet}\n",
    "    char_counts_x = pd.Series(char_counts_x)\n",
    "    \n",
    "    log_prob_x_given_y = {}\n",
    "    for y in classes:\n",
    "        log_prob_x_given_y[y] = (char_counts_x * np.log(class_cond_probs.loc[y])).sum()\n",
    "    log_prob_x_given_y = pd.Series(log_prob_x_given_y)\n",
    "\n",
    "    log_prob_y_given_x = {}\n",
    "    for y in classes:\n",
    "        log_prob_y_given_x[y] = log_prob_x_given_y.loc[y].item() + np.log(prior_probs.loc[y].item())\n",
    "    log_prob_y_given_x = pd.Series(log_prob_y_given_x)\n",
    "\n",
    "    y_pred = log_prob_y_given_x.idxmax()\n",
    "    return y_pred\n",
    "\n",
    "# prediction on test input from e10.txt\n",
    "x = [c for c in open(os.path.join(data_dir, 'e10.txt')).read() if c in alphabet]\n",
    "e_10_word_count = pd.Series({c: x.count(c) for c in alphabet})\n",
    "y_pred = predict(x)\n",
    "print(y_pred)\n",
    "print(e_10_word_count)\n",
    "\n",
    "r = 0\n",
    "i=0\n",
    "for c in alphabet:\n",
    "    r = r + e_10_word_count[c]*math.log(class_cond_probs.loc['e'][i])\n",
    "    i = i+1\n",
    "print(r)\n",
    "r = 0\n",
    "i=0\n",
    "for c in alphabet:\n",
    "    r = r + e_10_word_count[c]*math.log(class_cond_probs.loc['j'][i])\n",
    "    i = i+1\n",
    "print(r)\n",
    "r = 0\n",
    "i=0\n",
    "for c in alphabet:\n",
    "    r = r + e_10_word_count[c]*math.log(class_cond_probs.loc['s'][i])\n",
    "    i = i+1\n",
    "print(r)\n",
    "\n",
    "    \n",
    "    \n",
    "# shuffle x and predict again\n",
    "x_shuffled = random.sample(x, len(x))\n",
    "y_pred_shuffled = predict(x_shuffled)\n",
    "\n",
    "#evaluate predictions on all test data\n",
    "y_preds_test = [predict(x) for x in test_data]\n",
    "\n",
    "def make_confusion_matrix(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "        print('error: y_true and y_pred are different lengths')\n",
    "        exit()\n",
    "    confusion_matrix = pd.DataFrame(data=np.zeros((len(classes), len(classes))),\n",
    "                                    index=classes,\n",
    "                                    columns=classes)\n",
    "    for y_t, y_p in zip(y_true, y_pred):\n",
    "        confusion_matrix.loc[y_p][y_t] = confusion_matrix.loc[y_p][y_t] + 1\n",
    "\n",
    "    return confusion_matrix\n",
    "\n",
    "confusion_matrix_original = make_confusion_matrix(y_true=test_labels, y_pred=y_preds_test)\n",
    "print(confusion_matrix_original )\n",
    "\n",
    "\n",
    "#shuffling \n",
    "y_preds_test_shuffled = [predict(random.sample(x, len(x))) for x in test_data]\n",
    "confusion_matrix_shuffled = make_confusion_matrix(y_true=test_labels, y_pred=y_preds_test_shuffled)\n",
    "print(confusion_matrix_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5e6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bcc17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dcf8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
